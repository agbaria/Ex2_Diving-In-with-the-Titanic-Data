---
title: "ex2"
author: "Alaa Agbaria"
date: "November 29, 2017"
output: html_document
---

```{r}
train <- read.csv("train.csv",  na.strings = "")
test <- read.csv("test.csv", na.strings = "")
ids <- test$PassengerId
test$Survived <- NA
df <- rbind(train, test)
str(df)
```

## Preprocessing
I applied the same preprocessing for all the algorithems: [with help from the internet:)]

1. By looking at the passenger names, it seems that some of the passengers have a rare titles (Don, Countess, ..) and most of them have reqular titles (Mr, Mrs, ..). So perhaps those with rare titles who belong to the high society, had more chance to survive than the others.

2. The age feature is important for learning the model, but it has too many NA's:
```{r}
sum(is.na(df$Age))
```
so I will try to predict the missing age values.

***

First let's create a new feature called "Title", that will hold the passengers' titles:
```{r}
df$Title <- gsub('(.*, )|(\\..*)', '', df$Name)
```
Let's count the titles per passenger:
```{r}
table(df$Title)
```
There are 11 rare titles (Dona, Lady, the Countess, Capt, Col, Don, Dr, Major, Rev, Sir, Jonkheer), and four titles (Mlle, Ms, Mme, Master) that are equivalent to (Miss, Miss, Mrs, Mr) accordingly:
```{r}
rareTitles <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')

df$Title[df$Title == 'Mlle'] <- 'Miss' 
df$Title[df$Title == 'Ms'] <- 'Miss'
df$Title[df$Title == 'Mme'] <- 'Mrs'
df$Title[df$Title == 'Master'] <- 'Mr'
df$Title[df$Title %in% rareTitles] <- 'RareTitle'
```
```{r}
table(df$Title)
```

Converting some features to factor, and deleting the uuneeded ones:

```{r}
df$Survived <- as.factor(df$Survived)
df$Pclass <- as.factor(df$Pclass)
df$Title <- as.factor(df$Title)
df <- df[,-c(1,4,9,11)]
```
 
***
 
Now let's handle the missing Age values by imputation:
 
```{r results='hide', message=FALSE, warning=FALSE}
#install.packages("mice")
library(mice)
miceMod <- mice(df[, !names(df) %in% "Survived"], method="rf")
miceOutput <- complete(miceMod)
df$Age <- miceOutput$Age
```
```{r}
sum(is.na(df$Age))
```
Let's apply the same for the missing feature in Fare:
```{r}
df$Fare <- miceOutput$Fare
```

*That's it for preprocessing*

***

## Now let's do some predicting:

Spliting our data for train and test&evaluation:

```{r}
set.seed(123)
train <- df[1:891,] # The actual train data
test <- df[892:1309,]
indices <- sample(1:nrow(train), nrow(train) * 0.8)
ttrain <- train[indices,] 
ttest <- train[-indices,]
```

### randomforest from caret package:

```{r results='hide', message=FALSE, warning=FALSE}
library(caret)
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
fit.rf <- train(Survived ~ ., data = ttrain, method = "rf", ntree = 10,  metric = metric, trControl = control, tuneGrid = expand.grid(.mtry = c(5)), na.action = na.omit)
pred <- predict(fit.rf, ttest[, -1])
```
```{r}
mean(pred == ttest$Survived)
```

**predicting on test data**

```{r eval=FALSE}
library(caret)
control <- trainControl(method="cv", number=10)
metric <- "Accuracy"
fit.rf <- train(Survived ~ ., data = train, method = "rf", ntree = 10,  metric = metric, trControl = control, tuneGrid = expand.grid(.mtry = c(5)), na.action = na.omit)
pred <- predict(fit.rf, test)
res <- cbind(PassengerId = ids, Survived = as.character(pred))
write.csv(res, file="submissions/rf.csv", row.names = F)
```

Result: 0.76076
Rank: 7561

[Submitted file](https://github.com/agbaria/Ex2_Diving-In-with-the-Titanic-Data/blob/master/submissions/rf.csv)

![rf](/images/rf.png)

### randomforest from randomForest package:

```{r results='hide', message=FALSE, warning=FALSE}
library(randomForest)
model <- randomForest(Survived ~ ., data = ttrain, na.action = na.omit)
pred <- predict(model, ttest[, -1])
```
```{r}
mean(pred == ttest$Survived)
```

**predicting on test data**

```{r eval=FALSE}
library(randomForest)
model <- randomForest(Survived ~ ., data = train, na.action = na.omit)
pred <- predict(model, test)
res <- cbind(PassengerId = ids, Survived = as.character(pred))
write.csv(res, file="submissions/randomForest.csv", row.names = F)
```

Result: 0.78947
Rank: 3208

[Submitted file](https://github.com/agbaria/Ex2_Diving-In-with-the-Titanic-Data/blob/master/submissions/randomForest.csv)

![rf](/images/randomForest.png)

### Recursive Partitioning and Regression Trees (rpart):

```{r results='hide', message=FALSE, warning=FALSE}
library(rpart)
titanic.rpart <- rpart(Survived ~ ., data = ttrain, na.action = na.omit)

library(rattle)
library(rpart.plot)
```
```{r}
fancyRpartPlot(titanic.rpart)

pred <- predict(titanic.rpart, ttest[, -1], type = "class")
mean(pred == ttest$Survived)
```

**predicting on test data**

```{r eval=FALSE}
titanic.rpart <- rpart(Survived ~ ., data = train, na.action = na.omit)
pred <- predict(titanic.rpart, test, type = "class")
res <- cbind(PassengerId = ids, Survived = as.character(pred))
write.csv(res, file="submissions/rpart.csv", row.names = F)
```

Result: 0.79904
Rank: 

[Submitted file](https://github.com/agbaria/Ex2_Diving-In-with-the-Titanic-Data/blob/master/submissions/rpart.csv)

![rf](/images/rpart.png)

### SVM:

```{r results='hide', message=FALSE, warning=FALSE}
train1 <- data.matrix(train, rownames.force = T)
train1[,'Survived'] <- train1[,'Survived'] - 1
test1 <- data.matrix(test, rownames.force = T)
```

```{r results='hide', message=FALSE, warning=FALSE}
library(e1071)
train.svm <- svm(as.factor(Survived) ~ ., train1, cost = 1, kernel = 'linear')
pred <- predict(train.svm, test1[,-1])
res <- cbind(PassengerId = ids, Survived = as.character(pred))
write.csv(res, file="submissions/svm.csv", row.names = F)
```

Result: 0.76555

[Submitted file](https://github.com/agbaria/Ex2_Diving-In-with-the-Titanic-Data/blob/master/submissions/svm.csv)

![rf](/images/svm.png)

**The best table rank**

![rf](/images/rank.png)


### Ensemble

```{r}
levels(ttrain$Survived) <- c("n", "y")
levels(ttest$Survived) <- c("n", "y")
str(ttrain)
str(ttest)
```

```{r results='hide', message=FALSE, warning=FALSE}
library(caretEnsemble)
library(caret)
control <- trainControl(
  method="boot",
  number=25,
  savePredictions="final",
  classProbs=TRUE,
  summaryFunction=twoClassSummary
  )

model_list <- caretList(
  Survived ~ ., data=na.omit(ttrain),
  trControl=control,
  metric = "ROC",
  methodList=c("glm", "rpart")
)

p <- as.data.frame(predict(model_list, newdata=na.omit(ttest)))
```
```{r}
print(p)
```

```{r}
results <- resamples(model_list)
summary(results)
modelCor(results)
splom(results)
```

*Couldn't go any further from here. I searched alot for examples on how to use ensembles for classification, but got no Result*


